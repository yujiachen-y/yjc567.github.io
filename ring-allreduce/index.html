<!doctype html>
<html lang="en" data-theme="auto">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Introduction to Ring-Allreduce | Jiachen Yu</title>
        <meta name="description" content="Introduction to Ring-Allreduce" />
    <meta property="og:title" content="Introduction to Ring-Allreduce | Jiachen Yu" />
    <meta property="og:description" content="Introduction to Ring-Allreduce" />
    <meta property="og:type" content="article" />
    <meta property="og:url" content="https://www.yujiachen.com/ring-allreduce/" />
    <meta name="twitter:card" content="summary" />
    <link rel="canonical" href="https://www.yujiachen.com/ring-allreduce/" />
    <link rel="alternate" type="text/markdown" href="https://www.yujiachen.com/posts/ring-allreduce/post.md" />
    <link rel="alternate" hreflang="en" href="https://www.yujiachen.com/ring-allreduce/" />
<link rel="alternate" hreflang="zh" href="https://www.yujiachen.com/ring-allreduce/zh/" /> <link rel="alternate" type="application/rss+xml" title="RSS" href="https://www.yujiachen.com/rss.xml" />
<link rel="alternate" type="application/rss+xml" title="RSS (EN)" href="https://www.yujiachen.com/rss-en.xml" /> <link rel="icon" href="/favicon-32.png" type="image/png" sizes="32x32" />
<link rel="icon" href="/favicon.png" type="image/png" />
<link rel="icon" href="/favicon.ico" type="image/x-icon" />
<link rel="apple-touch-icon" href="/apple-touch-icon.png" sizes="180x180" /> <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&amp;family=Source+Serif+4:ital,wght@0,400;0,600;0,700;1,400&amp;family=Noto+Serif+SC:wght@400;600;700&amp;display=swap" />
    <link rel="stylesheet" href="/katex/katex.min.css" />
    <link rel="stylesheet" href="/styles.css" />
    <link rel="stylesheet" href="/fonts.css" />
  </head>
  <body data-page="post">
    <div id="root">
      
<nav class="navbar">
  <div class="nav-left">
    <a href="/" class="brand">Jiachen Yu</a>
    <div class="nav-links">
      <a class="nav-link-button" href="/about/" data-nav="about">About</a>
      <a class="nav-link-button" href="/blog/" data-nav="blog">Blog</a>
    </div>
  </div>
  <div class="controls">
    <div class="action-controls">
      <div class="lang-switcher" data-lang-switcher data-lang-switcher-mode="toggle">
        <button class="lang-toggle" type="button" data-lang-toggle>EN</button>
      </div>
      <div class="theme-switcher" data-theme-switcher data-theme-state="light">
        <button
          class="theme-trigger"
          type="button"
          data-theme-trigger
          aria-label="Theme mode toggle"
          aria-pressed="false"
        >
          <span class="theme-trigger-icon">
            <svg class="theme-icon theme-icon-dark" viewBox="0 0 24 24" aria-hidden="true">
              <path
                d="M21 12.8A8.5 8.5 0 1 1 11.2 3a7.5 7.5 0 0 0 9.8 9.8Z"
                fill="currentColor"
              />
            </svg>
            <svg class="theme-icon theme-icon-light" viewBox="0 0 24 24" aria-hidden="true">
              <circle cx="12" cy="12" r="4" fill="currentColor" />
              <path
                d="M12 3v2M12 19v2M4.9 4.9l1.4 1.4M17.7 17.7l1.4 1.4M3 12h2M19 12h2M4.9 19.1l1.4-1.4M17.7 6.3l1.4-1.4"
                stroke="currentColor"
                stroke-width="2"
                stroke-linecap="round"
                fill="none"
              />
            </svg>
          </span>
        </button>
      </div>
      <a
        class="ask-ai-entry"
        href="/ask-ai/"
        data-ask-ai-entry
        aria-label="Open Ask AI"
      >
        <span class="ask-ai-entry-label">Ask AI</span>
      </a>
    </div>
  </div>
</nav>

      <main class="page-shell article-page">
        <div class="article-layout no-toc page-shell-content">
          
          <div class="article-content">
            

<div class="article-text-content">
  <div class="article-date">2018-05-24 · TECH</div>
  <h1 class="article-hero">Introduction to Ring-Allreduce</h1>
  <div class="article-body"><p><em>Translated by Claude from the Chinese original.</em></p>
<p>Today I stumbled upon the ring-allreduce GPU communication algorithm out of curiosity. I originally wanted to read about it on <a href="http://research.baidu.com/bringing-hpc-techniques-deep-learning/">Baidu Research’s page</a>, but couldn’t find the relevant content on their site. After reading the comments in the <a href="https://github.com/baidu-research/baidu-allreduce">baidu-allreduce</a> code, I understood it. It’s actually a fairly simple algorithm to explain, so I’ll give a brief overview.</p>
<p>If you want implementation details, you can read the comments on GitHub directly—they’re very clear: <a href="https://github.com/baidu-research/baidu-allreduce/blob/master/collectives.cu#L156">https://github.com/baidu-research/baidu-allreduce/blob/master/collectives.cu#L156</a></p>
<ul>
<li><em>Unless otherwise noted, the images in this post are from <a href="https://www.zhihu.com/question/57799212/answer/292494636?utm_source=ZHShareTargetIDMore&amp;utm_medium=social&amp;utm_oi=37729630945280">a Zhihu answer</a>, because I could not find the original Baidu Research article containing these diagrams.</em></li>
</ul>
<p>A major drawback of typical multi-GPU training is that one GPU needs to collect gradients from all other GPUs each time, then distribute the updated model back to all other GPUs. As shown below:</p>
<p>
<picture>
  <source srcset="/assets/posts/ring-allreduce/en/image_1.webp" type="image/webp" />
  <img src="/assets/posts/ring-allreduce/en/image_1.png" alt="" class="article-image" width="452" height="310" />
</picture>
</p>
<p>The biggest drawback of this model is that GPU 0’s communication time grows linearly with the number of GPUs. This is why ring-allreduce was developed, as shown below:</p>
<p>
<picture>
  <source srcset="/assets/posts/ring-allreduce/en/image_2.webp" type="image/webp" />
  <img src="/assets/posts/ring-allreduce/en/image_2.png" alt="" class="article-image" width="419" height="330" />
</picture>

The basic idea of this algorithm is to eliminate the central reducer and let data flow through a ring formed by the GPUs. The entire ring-allreduce process consists of two major steps: the first step is reduce-scatter, and the second step is allgather.</p>
<p>First step (reduce-scatter): We have n GPUs. We divide the data on each GPU into n equal chunks and assign each GPU its left and right neighbors (in the diagram, GPU 0’s left neighbor is GPU 4 and right neighbor is GPU 1; GPU 1’s left neighbor is GPU 0 and right neighbor is GPU 2, and so on). Then we perform n-1 rounds. In round i, GPU j sends its chunk (j - i) mod n to GPU j+1 and receives chunk (j - i - 1) mod n from GPU j-1, then performs a reduce operation on the received data. (All indices use modulo-n wrap-around, e.g., -1 mod n = n - 1.) The diagram below illustrates this:</p>
<p>
<picture>
  <source srcset="/assets/posts/ring-allreduce/en/image_3.webp" type="image/webp" />
  <img src="/assets/posts/ring-allreduce/en/image_3.png" alt="" class="article-image" width="480" height="335" />
</picture>

After n-1 rounds, the first step (reduce-scatter) of ring-allreduce is complete. At this point, each GPU holds one fully reduced chunk. The algorithm then enters allgather, which also takes n-1 rounds.</p>
<p>The second step, allgather, is straightforward: through n-1 rounds, each GPU forwards its reduced chunk to other GPUs. In round i, GPU j sends its (j - i - 1) mod n chunk to its right neighbor and receives the (j - i - 2) mod n chunk from its left neighbor. Unlike the first step, the received data does not need a reduce operation; it is copied directly into place.</p>
<p>Finally, the data on each GPU looks like this:</p>
<p>
<picture>
  <source srcset="/assets/posts/ring-allreduce/en/image_4.webp" type="image/webp" />
  <img src="/assets/posts/ring-allreduce/en/image_4.png" alt="" class="article-image" width="572" height="321" />
</picture>

If it’s still unclear, let’s walk through a 3-GPU example:</p>
<p>First, the reduce-scatter step:</p>
<p>
<picture>
  <source srcset="/assets/posts/ring-allreduce/en/image_5.webp" type="image/webp" />
  <img src="/assets/posts/ring-allreduce/en/image_5.png" alt="" class="article-image" width="772" height="913" />
</picture>
</p>
<p>Then the allgather step:</p>
<p>
<picture>
  <source srcset="/assets/posts/ring-allreduce/en/image_6.webp" type="image/webp" />
  <img src="/assets/posts/ring-allreduce/en/image_6.png" alt="" class="article-image" width="1080" height="1321" />
</picture>
</p>
<p>References:</p>
<p><a href="https://github.com/baidu-research/baidu-allreduce">https://github.com/baidu-research/baidu-allreduce</a></p>
<p><a href="https://www.zhihu.com/question/57799212/answer/292494636?utm_source=ZHShareTargetIDMore&amp;utm_medium=social&amp;utm_oi=37729630945280">https://www.zhihu.com/question/57799212/answer/292494636?utm_source=ZHShareTargetIDMore&amp;utm_medium=social&amp;utm_oi=37729630945280</a></p>
</div>
</div>

            <section class="citation-section" data-citation-section></section>
            <section class="comment-section" data-comment-section></section>
          </div>
        </div>
      </main>
    </div>

    <script id="page-data" type="application/json">
      {
  "pageType": "post",
  "lang": "en",
  "langSwitchUrl": "/ring-allreduce/zh/",
  "langSwitcherMode": "toggle",
  "markdownUrl": "/posts/ring-allreduce/post.md",
  "labels": {
    "navAbout": "About",
    "navBlog": "Blog",
    "filterAll": "All"
  },
  "comments": {
    "appId": "e224d3ce-6f5a-4777-bb80-b7bbf2e78d83",
    "pageId": "ring-allreduce",
    "pageUrl": "https://www.yujiachen.com/ring-allreduce/",
    "pageTitle": "Introduction to Ring-Allreduce"
  }
}
    </script>
    <script type="module" src="/app.js"></script>
  </body>
</html>
